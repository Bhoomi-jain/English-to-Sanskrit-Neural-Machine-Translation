{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f50f04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f746c3",
   "metadata": {},
   "source": [
    "Path → safe file handling   \n",
    "random → data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73cc970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_RAW = Path(\"data/raw\")     #original untouched data(read-only)\n",
    "DATA_PROCESSED = Path(\"data/processed\")     #cleaned + merged data will go(model reads from here)\n",
    "TOKENIZER_DIR = Path(\"tokenizer\")       #SentencePiece models will be saved here\n",
    "\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)       #Creates folders only if they don’t exist\n",
    "TOKENIZER_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5265ffa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BPCC\n",
    "bpcc_en = (DATA_RAW / \"bpcc/train.en\").read_text(encoding=\"utf-8\").splitlines()\n",
    "bpcc_sa = (DATA_RAW / \"bpcc/train.sa\").read_text(encoding=\"utf-8\").splitlines()\n",
    "\n",
    "# Samayik\n",
    "sam_train_en = (DATA_RAW / \"samayik/train.en\").read_text(encoding=\"utf-8\").splitlines()\n",
    "sam_train_sa = (DATA_RAW / \"samayik/train.sa\").read_text(encoding=\"utf-8\").splitlines()\n",
    "\n",
    "sam_dev_en = (DATA_RAW / \"samayik/dev.en\").read_text(encoding=\"utf-8\").splitlines()\n",
    "sam_dev_sa = (DATA_RAW / \"samayik/dev.sa\").read_text(encoding=\"utf-8\").splitlines()\n",
    "\n",
    "sam_test_en = (DATA_RAW / \"samayik/test.en\").read_text(encoding=\"utf-8\").splitlines()\n",
    "sam_test_sa = (DATA_RAW / \"samayik/test.sa\").read_text(encoding=\"utf-8\").splitlines()\n",
    "\n",
    "# Load Itihasa (parallel, aligned)\n",
    "iti_train_en = (DATA_RAW / \"itihasa/train.en\").read_text(encoding=\"utf-8\").splitlines()\n",
    "iti_train_sa = (DATA_RAW / \"itihasa/train.sn\").read_text(encoding=\"utf-8\").splitlines()\n",
    "\n",
    "iti_dev_en = (DATA_RAW / \"itihasa/dev.en\").read_text(encoding=\"utf-8\").splitlines()\n",
    "iti_dev_sa = (DATA_RAW / \"itihasa/dev.sn\").read_text(encoding=\"utf-8\").splitlines()\n",
    "\n",
    "iti_test_en = (DATA_RAW / \"itihasa/test.en\").read_text(encoding=\"utf-8\").splitlines()\n",
    "iti_test_sa = (DATA_RAW / \"itihasa/test.sn\").read_text(encoding=\"utf-8\").splitlines()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a59aef",
   "metadata": {},
   "source": [
    "Each file is read as UTF-8 (mandatory for Devanagari), split by newline, becomes List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b04e849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BPCC: 98788 99424\n",
      "Samayik train: 43493 43493\n",
      "Samayik dev: 2416 2416\n",
      "Samayik test: 2417 2417\n",
      "Itihasa train: 75161 75161\n",
      "Itihasa dev: 6148 6148\n",
      "Itihasa test: 11721 11721\n"
     ]
    }
   ],
   "source": [
    "print(\"BPCC:\", len(bpcc_en), len(bpcc_sa))\n",
    "\n",
    "print(\"Samayik train:\", len(sam_train_en), len(sam_train_sa))\n",
    "print(\"Samayik dev:\", len(sam_dev_en), len(sam_dev_sa))\n",
    "print(\"Samayik test:\", len(sam_test_en), len(sam_test_sa))\n",
    "\n",
    "print(\"Itihasa train:\", len(iti_train_en), len(iti_train_sa))\n",
    "print(\"Itihasa dev:\", len(iti_dev_en), len(iti_dev_sa))\n",
    "print(\"Itihasa test:\", len(iti_test_en), len(iti_test_sa))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d9932a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was no Mughal tradition of primogeniture, the systematic passing of rule, upon an emperor's death, to his eldest son.\n",
      "चक्रवर्तिनः मृत्योः अनन्तरं तस्य शासनस्य व्यवस्थितरूपेण सङ्क्रमणस्य, मुघलपरम्परायाः ज्येष्ठपुत्राधिकारपद्धतिः नासीत्।\n"
     ]
    }
   ],
   "source": [
    "print(bpcc_en[0])\n",
    "print(bpcc_sa[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca28e03",
   "metadata": {},
   "source": [
    "BPCC data is mismatched and not aligned, we'll use it for tokenizer training, not for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25513f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN: A king should also consult such minister as are free from the five kinds of deceit.\n",
      "SA: संविनीय मदक्रोधौ मानमर्त्यां च निवृताः। नित्यं पञ्चोपधातीतैर्मन्त्रयेत् सह मन्त्रिभिः॥\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0, len(iti_train_en) - 1)\n",
    "print(\"EN:\", iti_train_en[i])\n",
    "print(\"SA:\", iti_train_sa[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e33952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN: That is because we were in level 3 when we closed Ktouch.\n",
      "SA: यतो हि यदा वयं के-टच पिहितवन्तः तदा तृतीयस्तरे एव आस्म।\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0, len(sam_train_en) - 1)\n",
    "print(\"EN:\", sam_train_en[i])\n",
    "print(\"SA:\", sam_train_sa[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2a9afc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final TRAIN size: 118654\n"
     ]
    }
   ],
   "source": [
    "# Translation training corpus\n",
    "train_en = sam_train_en + iti_train_en\n",
    "train_sa = sam_train_sa + iti_train_sa\n",
    "\n",
    "print(\"Final TRAIN size:\", len(train_en))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e6702e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer corpus:\n",
      "EN sentences: 217442\n",
      "SA sentences: 218078\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer corpus \n",
    "tok_en = bpcc_en + train_en\n",
    "tok_sa = bpcc_sa + train_sa\n",
    "\n",
    "print(\"Tokenizer corpus:\")\n",
    "print(\"EN sentences:\", len(tok_en))\n",
    "print(\"SA sentences:\", len(tok_sa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad05e270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN sentences: 118654\n",
      "EN min: 1\n",
      "EN max: 1306\n",
      "EN avg: 24.342188211101185\n"
     ]
    }
   ],
   "source": [
    "en_lengths = [len(s.split()) for s in train_en if s.strip()]\n",
    "\n",
    "print(\"EN sentences:\", len(en_lengths))\n",
    "print(\"EN min:\", min(en_lengths))\n",
    "print(\"EN max:\", max(en_lengths))\n",
    "print(\"EN avg:\", sum(en_lengths) / len(en_lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42b4b0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA sentences: 118654\n",
      "SA min: 1\n",
      "SA max: 2688\n",
      "SA avg: 87.45049471572808\n"
     ]
    }
   ],
   "source": [
    "sa_lengths = [len(s) for s in train_sa if s.strip()]\n",
    "\n",
    "print(\"SA sentences:\", len(sa_lengths))\n",
    "print(\"SA min:\", min(sa_lengths))\n",
    "print(\"SA max:\", max(sa_lengths))\n",
    "print(\"SA avg:\", sum(sa_lengths) / len(sa_lengths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9c72e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25313780"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(DATA_PROCESSED / \"tok_en.txt\").write_text(\n",
    "    \"\\n\".join(tok_en),\n",
    "    encoding=\"utf-8\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10c2d2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19646646"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(DATA_PROCESSED / \"tok_sa.txt\").write_text(\n",
    "    \"\\n\".join(tok_sa),\n",
    "    encoding=\"utf-8\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c35ff476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English tokenizer already exists. Skipping training.\n"
     ]
    }
   ],
   "source": [
    "# Train English tokenizer ONLY if it doesn't exist\n",
    "if not (TOKENIZER_DIR / \"spm_en.model\").exists():\n",
    "    import sentencepiece as spm\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=str(DATA_PROCESSED / \"tok_en.txt\"),\n",
    "        model_prefix=str(TOKENIZER_DIR / \"spm_en\"),\n",
    "        vocab_size=16000,\n",
    "        model_type=\"unigram\",\n",
    "        character_coverage=1.0,\n",
    "        pad_id=0,\n",
    "        bos_id=1,\n",
    "        eos_id=2,\n",
    "        unk_id=3\n",
    "    )\n",
    "else:\n",
    "    print(\"English tokenizer already exists. Skipping training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8c29c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanskrit tokenizer already exists. Skipping training.\n"
     ]
    }
   ],
   "source": [
    "# Train Sanskrit tokenizer ONLY if it doesn't exist\n",
    "if not (TOKENIZER_DIR / \"spm_sa.model\").exists():\n",
    "    import sentencepiece as spm\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=str(DATA_PROCESSED / \"tok_sa.txt\"),\n",
    "        model_prefix=str(TOKENIZER_DIR / \"spm_sa\"),\n",
    "        vocab_size=32000,\n",
    "        model_type=\"unigram\",\n",
    "        character_coverage=1.0,\n",
    "        pad_id=0,\n",
    "        bos_id=1,\n",
    "        eos_id=2,\n",
    "        unk_id=3\n",
    "    )\n",
    "else:\n",
    "    print(\"Sanskrit tokenizer already exists. Skipping training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bf8942",
   "metadata": {},
   "source": [
    "TOKENIZER (RUN ONCE ONLY)\n",
    "DO NOT RETRAIN UNLESS DATA CHANGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "642b15c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 2050\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a48ff04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b1bdb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "sp_en = spm.SentencePieceProcessor()\n",
    "sp_en.load(\"tokenizer/spm_en.model\")\n",
    "\n",
    "sp_sa = spm.SentencePieceProcessor()\n",
    "sp_sa.load(\"tokenizer/spm_sa.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bd4c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SRC_LEN = 128\n",
    "MAX_TGT_LEN = 128\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "train_en_ids = [\n",
    "    sp_en.encode(s, out_type=int)[:MAX_SRC_LEN]\n",
    "    for s in train_en\n",
    "]\n",
    "\n",
    "train_sa_ids = [\n",
    "    sp_sa.encode(s, out_type=int)[:MAX_TGT_LEN]\n",
    "    for s in train_sa\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04ef9955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(x) for x in train_sa_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8e69297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src, tgt):\n",
    "        self.src = src\n",
    "        self.tgt = tgt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.src[idx], dtype=torch.long),\n",
    "            torch.tensor(self.tgt[idx], dtype=torch.long)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa7263b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "PAD_ID = 0\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "\n",
    "    src_pad = pad_sequence(\n",
    "        src_batch,\n",
    "        batch_first=True,\n",
    "        padding_value=PAD_ID\n",
    "    )\n",
    "\n",
    "    tgt_pad = pad_sequence(\n",
    "        tgt_batch,\n",
    "        batch_first=True,\n",
    "        padding_value=PAD_ID\n",
    "    )\n",
    "\n",
    "    return src_pad, tgt_pad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a49c0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds = TranslationDataset(train_en_ids, train_sa_ids)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "044a6ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TranslationDataset(train_en_ids, train_sa_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c711bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3708\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1823a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) *\n",
    "            (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05222e00",
   "metadata": {},
   "source": [
    "- pe = torch.zeros(max_len, d_model):\n",
    "Matrix storing positional vectors. Ex: 5000 × 512\n",
    "\n",
    "- position = torch.arange(0, max_len).unsqueeze(1):\n",
    "Creates: [[0],\n",
    " [1],\n",
    " [2],\n",
    " ...\n",
    "]\n",
    "\n",
    "- div_term:\n",
    "Controls frequency scaling.\n",
    "Lower dimensions → slow variation,\n",
    "Higher dimensions → fast variation.\n",
    "This allows model to infer relative distances.\n",
    "\n",
    "- sin and cos:\n",
    "Alternating dimensions: This creates unique positional signatures.\n",
    "dim0 → sin\n",
    "dim1 → cos\n",
    "dim2 → sin\n",
    "dim3 → cos\n",
    "\n",
    "- register_buffer:\n",
    "    moves with model to GPU, not trainable, saved in checkpoints\n",
    "\n",
    "- forward: Adds positional information to embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50d1450a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "pe = PositionalEncoding(d_model=512)\n",
    "\n",
    "x = torch.zeros(2, 10, 512)  # batch=2, seq_len=10\n",
    "out = pe(x)\n",
    "\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21002b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        d_k = Q.size(-1)\n",
    "\n",
    "        # Attention scores\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "\n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, torch.finfo(scores.dtype).min)\n",
    "\n",
    "        # Attention weights\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = torch.matmul(attn, V)\n",
    "\n",
    "        return output, attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "610bc5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 64])\n",
      "torch.Size([2, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "attn = ScaledDotProductAttention()\n",
    "\n",
    "Q = torch.randn(2, 5, 64)\n",
    "K = torch.randn(2, 5, 64)\n",
    "V = torch.randn(2, 5, 64)\n",
    "\n",
    "out, weights = attn(Q, K, V)\n",
    "\n",
    "print(out.shape)\n",
    "print(weights.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b74af2e",
   "metadata": {},
   "source": [
    "A single attention head can only learn one type of relationship at a time.\n",
    "But language has many relationships simultaneously. So instead of 1 attention we use multiple attention heads in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e261ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "\n",
    "        # Linear projections\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.attention = ScaledDotProductAttention()\n",
    "\n",
    "        # Final output projection\n",
    "        self.fc_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "\n",
    "        x = x.view(batch_size, seq_len,\n",
    "                   self.num_heads, self.head_dim)\n",
    "\n",
    "        return x.transpose(1, 2)\n",
    "        # (batch, heads, seq_len, head_dim)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, heads, seq_len, head_dim = x.size()\n",
    "\n",
    "        x = x.transpose(1, 2).contiguous()\n",
    "\n",
    "        return x.view(batch_size, seq_len,\n",
    "                      heads * head_dim)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "\n",
    "        Q = self.W_q(Q)\n",
    "        K = self.W_k(K)\n",
    "        V = self.W_v(V)\n",
    "\n",
    "        Q = self.split_heads(Q)\n",
    "        K = self.split_heads(K)\n",
    "        V = self.split_heads(V)\n",
    "\n",
    "        out, attn = self.attention(Q, K, V, mask)\n",
    "\n",
    "        out = self.combine_heads(out)\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e21ddc",
   "metadata": {},
   "source": [
    "**FEED FORWARD NETWORK (FFN)**\n",
    "\n",
    "Attention mixes information between tokens.\n",
    "But we also need a mechanism that:\n",
    "transforms features, adds non-linearity, increases representational power\n",
    "\n",
    "This is what the Feed Forward Network does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a7716ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2165a1b8",
   "metadata": {},
   "source": [
    "- ReLU: Adds non-linearity. Without this, model becomes linear → weak.\n",
    "- Dropout: Prevents overfitting. Important for MT tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43670550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "ffn = FeedForward(512, 2048)\n",
    "\n",
    "x = torch.randn(2, 10, 512)\n",
    "\n",
    "out = ffn(x)\n",
    "\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653c54ca",
   "metadata": {},
   "source": [
    "**ENCODER LAYER (PRE-LAYERNORM):**\n",
    "\n",
    "Input\n",
    "  ->\n",
    "LayerNorm\n",
    "  ->\n",
    "Multi-Head Self Attention\n",
    "  ->\n",
    "Residual Add\n",
    "  ->\n",
    "LayerNorm\n",
    "  ->\n",
    "Feed Forward Network\n",
    "  ->\n",
    "Residual Add\n",
    "  ->\n",
    "Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "954b616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = FeedForward(d_model, d_ff, dropout)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "\n",
    "        # ---- Self Attention ----\n",
    "        attn_out = self.self_attn(\n",
    "            self.norm1(x),\n",
    "            self.norm1(x),\n",
    "            self.norm1(x),\n",
    "            mask\n",
    "        )\n",
    "\n",
    "        x = x + self.dropout(attn_out)\n",
    "\n",
    "        # ---- Feed Forward ----\n",
    "        ffn_out = self.ffn(self.norm2(x))\n",
    "\n",
    "        x = x + self.dropout(ffn_out)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8761b4",
   "metadata": {},
   "source": [
    "- LayerNorm before attention(self.norm1(x)): Normalizes input distribution → stable training.\n",
    "- Self-attention: Q = K = V = x\n",
    "Each token attends to every other token.\n",
    "- Residual connection: x = x + attn_out\n",
    "Preserves original information and improves gradient flow.\n",
    "- Feed Forward:\n",
    "Each token independently transforms its features.\n",
    "- Second residual connection: Again stabilizes deep stacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23773873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "enc_layer = EncoderLayer(\n",
    "    d_model=512,\n",
    "    num_heads=8,\n",
    "    d_ff=2048\n",
    ")\n",
    "\n",
    "x = torch.randn(2, 10, 512)\n",
    "\n",
    "out = enc_layer(x)\n",
    "\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b995530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        d_model,\n",
    "        num_heads,\n",
    "        d_ff,\n",
    "        num_layers,\n",
    "        dropout=0.1,\n",
    "        max_len=5000\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "\n",
    "        # Token embedding + scaling\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # Add positional encoding\n",
    "        x = self.pos_encoding(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Pass through encoder layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d982119d",
   "metadata": {},
   "source": [
    "- Embedding scaling: Prevents positional encoding from dominating embeddings early in training. This comes from the original paper.\n",
    "- Positional encoding:\n",
    "Adds order information.\n",
    "- ModuleList: \n",
    "Stores multiple encoder layers.\n",
    "Each layer has independent parameters.\n",
    "- Sequential processing: \n",
    "Each layer refines representation further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b107efdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "encoder = Encoder(\n",
    "    vocab_size=32000,\n",
    "    d_model=512,\n",
    "    num_heads=8,\n",
    "    d_ff=2048,\n",
    "    num_layers=6\n",
    ")\n",
    "\n",
    "x = torch.randint(0, 32000, (2, 10))\n",
    "\n",
    "out = encoder(x)\n",
    "\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03d81cc",
   "metadata": {},
   "source": [
    "The encoder only understands English.\n",
    "The decoder generates Sanskrit.\n",
    "\n",
    "- Encoder layer has:\n",
    "Self-Attention → FFN\n",
    "- Decoder layer has three blocks: ️Masked Self-Attention, Encoder–Decoder Attention,  Feed Forward Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff9305f",
   "metadata": {},
   "source": [
    "**Decoder Layer Structure:**\n",
    "Input\n",
    " ->\n",
    "LayerNorm\n",
    " ->\n",
    "Masked Self Attention\n",
    " ->\n",
    "Residual Add\n",
    " ->\n",
    "LayerNorm\n",
    " ->\n",
    "Cross Attention (Encoder output)\n",
    " ->\n",
    "Residual Add\n",
    " ->\n",
    "LayerNorm\n",
    " ->\n",
    "Feed Forward\n",
    " ->\n",
    "Residual Add\n",
    " ->\n",
    "Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "347a8acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = FeedForward(d_model, d_ff, dropout)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, tgt_mask=None, src_mask=None):\n",
    "\n",
    "        # ---- Masked Self Attention ----\n",
    "        self_attn_out = self.self_attn(\n",
    "            self.norm1(x),\n",
    "            self.norm1(x),\n",
    "            self.norm1(x),\n",
    "            tgt_mask\n",
    "        )\n",
    "\n",
    "        x = x + self.dropout(self_attn_out)\n",
    "\n",
    "        # ---- Encoder-Decoder Attention ----\n",
    "        cross_attn_out = self.cross_attn(\n",
    "            self.norm2(x),\n",
    "            enc_out,\n",
    "            enc_out,\n",
    "            src_mask\n",
    "        )\n",
    "\n",
    "        x = x + self.dropout(cross_attn_out)\n",
    "\n",
    "        # ---- Feed Forward ----\n",
    "        ffn_out = self.ffn(self.norm3(x))\n",
    "\n",
    "        x = x + self.dropout(ffn_out)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c0fec3",
   "metadata": {},
   "source": [
    "- Masked Self Attention: Decoder attends only to previous generated tokens.\n",
    "- Cross Attention:\n",
    "Decoder looks at encoder output.\n",
    "- Feed Forward:\n",
    "Token-level transformation again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de715b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "dec_layer = DecoderLayer(\n",
    "    d_model=512,\n",
    "    num_heads=8,\n",
    "    d_ff=2048\n",
    ")\n",
    "\n",
    "x = torch.randn(2, 10, 512)\n",
    "enc_out = torch.randn(2, 10, 512)\n",
    "\n",
    "out = dec_layer(x, enc_out)\n",
    "\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d698b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        d_model,\n",
    "        num_heads,\n",
    "        d_ff,\n",
    "        num_layers,\n",
    "        dropout=0.1,\n",
    "        max_len=5000\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x, enc_out, tgt_mask=None, src_mask=None):\n",
    "\n",
    "        # Embedding + scaling\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # Positional encoding\n",
    "        x = self.pos_encoding(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Pass through decoder layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_out, tgt_mask, src_mask)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95f8b26",
   "metadata": {},
   "source": [
    "- Embedding scaling: Same reason as encoder, stabilizes early training.\n",
    "- Decoder layers: Refines generation, aligns with encoder output better.\n",
    "- Mask handling: causal mask, padding mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "521b0d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "decoder = Decoder(\n",
    "    vocab_size=32000,\n",
    "    d_model=512,\n",
    "    num_heads=8,\n",
    "    d_ff=2048,\n",
    "    num_layers=6\n",
    ")\n",
    "\n",
    "tgt = torch.randint(0, 32000, (2, 10))\n",
    "enc_out = torch.randn(2, 10, 512)\n",
    "\n",
    "out = decoder(tgt, enc_out)\n",
    "\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b694ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size,\n",
    "        tgt_vocab_size,\n",
    "        d_model=512,\n",
    "        num_heads=8,\n",
    "        num_layers=6,\n",
    "        d_ff=2048,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            src_vocab_size,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            d_ff,\n",
    "            num_layers,\n",
    "            dropout\n",
    "        )\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            tgt_vocab_size,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            d_ff,\n",
    "            num_layers,\n",
    "            dropout\n",
    "        )\n",
    "\n",
    "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src,\n",
    "        tgt,\n",
    "        src_mask=None,\n",
    "        tgt_mask=None\n",
    "    ):\n",
    "\n",
    "        enc_out = self.encoder(src, src_mask)\n",
    "\n",
    "        dec_out = self.decoder(\n",
    "            tgt,\n",
    "            enc_out,\n",
    "            tgt_mask,\n",
    "            src_mask\n",
    "        )\n",
    "\n",
    "        out = self.fc_out(dec_out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b8c32",
   "metadata": {},
   "source": [
    "- Encoder: Processes English sentence into contextual vectors.\n",
    "- Decoder: Uses previous Sanskrit tokens, encoder output to generate next token representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d8bf964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10, 32000])\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=16000,\n",
    "    tgt_vocab_size=32000\n",
    ")\n",
    "\n",
    "src = torch.randint(0, 16000, (2, 10))\n",
    "tgt = torch.randint(0, 32000, (2, 10))\n",
    "\n",
    "out = model(src, tgt)\n",
    "\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee115d",
   "metadata": {},
   "source": [
    "**MASKING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dcdde4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq, pad_id=0):\n",
    "    return (seq != pad_id).unsqueeze(1).unsqueeze(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9600061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_causal_mask(size):\n",
    "    mask = torch.tril(torch.ones(size, size))\n",
    "    return mask.bool()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32711fe",
   "metadata": {},
   "source": [
    "**LOSS FUNCTION (LABEL SMOOTHING)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "658f62ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(\n",
    "    ignore_index=0,\n",
    "    label_smoothing=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a67bb6c",
   "metadata": {},
   "source": [
    "**OPTIMIZER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bebb9430",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,\n",
    "    betas=(0.9, 0.98),\n",
    "    eps=1e-9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45320289",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23f74ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14651/2340218076.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "528a03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d022df",
   "metadata": {},
   "source": [
    "**TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21abd30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, scaler, device):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for step, (src, tgt) in enumerate(loader):\n",
    "\n",
    "\n",
    "        src = src.to(device, non_blocking=True)\n",
    "        tgt = tgt.to(device, non_blocking=True)\n",
    "\n",
    "        # Teacher forcing split\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "\n",
    "        # Masks\n",
    "        src_mask = create_padding_mask(src).to(device)\n",
    "\n",
    "        tgt_mask = create_padding_mask(tgt_input).to(device)\n",
    "        causal_mask = create_causal_mask(\n",
    "            tgt_input.size(1)\n",
    "        ).to(device)\n",
    "\n",
    "        tgt_mask = tgt_mask & causal_mask.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "\n",
    "            output = model(\n",
    "                src,\n",
    "                tgt_input,\n",
    "                src_mask,\n",
    "                tgt_mask\n",
    "            )\n",
    "\n",
    "            output = output.reshape(-1, output.size(-1))\n",
    "            tgt_output = tgt_output.reshape(-1)\n",
    "\n",
    "            loss = criterion(output, tgt_output)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4005fa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14651/714903418.py:29: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 22.0577\n",
      "Epoch 2: Loss = 7.5415\n",
      "Epoch 3: Loss = 7.0613\n",
      "Epoch 4: Loss = 6.8028\n",
      "Epoch 5: Loss = 6.6203\n",
      "Epoch 6: Loss = 6.4790\n",
      "Epoch 7: Loss = 6.3626\n",
      "Epoch 8: Loss = 6.2658\n",
      "Epoch 9: Loss = 6.1834\n",
      "Epoch 10: Loss = 6.1120\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        scaler,\n",
    "        device\n",
    "    )\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a18db7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
